---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Lauren Hart"
date: '11/08/2020'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

```{r}
#classification diagnostics function:
class_diag<-function(probs,truth){
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE){
    truth<-as.numeric(truth)-1}
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}
```


#0. Introdcution
```{r}
#loading the dataset and minor adjustments: 
library(tidyverse)
forestfires <- read_csv("forestfires.csv") %>% as.data.frame
forestdata <- forestfires %>% mutate(logarea = log1p(area))
#mean centering variables: 
forestdata <- forestdata %>% mutate(meantemp = temp- mean(temp)) %>% mutate(meanRH = RH- mean(RH)) %>% mutate(meanwind = wind- mean(wind)) %>% mutate(meanlogarea = logarea- mean(logarea)) %>% mutate(meanDC = DC - mean(DC)) %>% mutate(meanISI = ISI - mean(ISI)) %>% mutate(meanrain = rain - mean(rain))
```

*This dataset was generated by Paulo Cortez and Aniíbal Morais from the University of Minho in Portugal. The dataset has information about 517 indepdendent forest fires from January 2000 to Decemner 2003 and the relevant weather patterns and indices from Montesinho natural park in the Northeast region of Portugal. The dataset includes basic weather pattern variables such as outside temperature (`temp`, Celsius), outside relative humidity (`RH`, %), outside wind speed (`wind`, km/hr), and outside rain (`rain`, mm/mm^2).  There are identifying variables for the x and y-axis coordinate of the fire (`X`, `Y`) and the month and day of the year that the fire took place (`month`, `day`). There are also indices that explain the conditions prior to a fire as well as the behavior of the fire. The drought code (`DC`, represents drying deep into the soil) and initial spread index (`ISI`, estimates a spread potential by integrating fuel moisture for fine dead fuels and windspeed) are the two indeces I will use along with the other variables listed above to predict forest fire area (`area`, hectares.). The area variable had to be log transformed due to its' tendency to go towards zero. The paper that this data comes from and explains how it  was created, merged, and analyzed for further studies can be found at this link: <http://piano.dsi.uminho.pt/~pcortez/fires.pdf>.*

#1. MANOVA test 
```{r, fig.width = 1}
#checking MANOVA assumptions: 
#multivariate normality: 
forestdata %>% group_by(day) %>% count()

#homogeneity of within-groupcovariance matrices: 
covmats <- forestdata %>% group_by(day) %>% do(covs=cov(.[5:11]))
for(i in 1:7){print(as.character(covmats$day[i])); print(covmats$covs[[i]])}

#MANOVA test: 
manforest <- manova(cbind(meanlogarea, meanDC, meanISI, meantemp, meanRH, meanwind, meanrain) ~ day, data = forestdata)
summary(manforest)

#univariate ANOVA: 
summary.aov(manforest)

#post-hoc tests: 
pairwise.t.test(forestdata$RH, forestdata$day, p.adj = "none")
pairwise.t.test(forestdata$ISI, forestdata$day, p.adj = "none")
```
*The null hypothesis of this MANOVA is that all of the response variables (DC, ISI, temp, RH, rain, and area) do not show a mean difference across days of the week. The alternate hypothesis is that at least one of the response variables (area, DC, ISI, temp, RH, rain, and area) does show a mean difference across days of the week. For MANOVA assumptions: the data has independent observations and it includes all of the forest fires between January 2000 to December 2003. Multivariate normality is met because each day of the week has more than 25 observations. The data fails the homogeneity of covariances as the covariances are extremely scattered. The data is not likely to pass the linearity assumption, multicollinearity, or extreme outliers assumptions as some of the variables are going to be more correlated than others due to them being related to weather patterns, and some may have outliers due to adverse weather conditions seen when forest fires begin. After running the MANOVA test and getting a significant p-value (p = 8.66e-05, df = 42, F = 2.0486), we can reject the null hypothesis and conclude that for at least one response variable, at least one day mean is different. Due to the significant result, 6 one-way ANOVA's were ran to analyze which response variable means were actually different. With the alpha value adjusted using the bonferroni correction ,the new alpha value is 0.0083 (7 tests ran total). Only RH and ISI are significant after this correction and have significantly different means for each day. Post-hoc tests were ran for these two variables. The adjusted alpha value after the MANOVA, univariate ANOVA's, and posthoc tests (9 tests total) would be 0.0055. For RH, the days that the mean RH significnatly differs are Sunday from Wednesday and Thursday and Thursday from Friday. For ISI, the days that the mean ISI significantly differs are Monday from Tuesday, Wednesday, and Friday, as well as Saturday from Wednesday. After 9 tests were ran in total, the probability of making a type I error is 0.3698 (36.98% chance).*

#2. Randomization test
```{R, dplyr.summarise.inform=F}
#observed F-statistic: 
forestdata <- forestdata %>% mutate(as.factor(day))
forestaov <- aov(meanlogarea ~ day, data = forestdata)
summary.aov(forestaov)
#generating random distribution: 
obs_F<-0.357 
Fs<-replicate(5000,{ 
new<-forestdata%>%mutate(logarea=sample(logarea)) 
SSW<- new%>%group_by(day)%>%summarize(SSW=sum((logarea-mean(logarea))^2))%>%
summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(logarea))%>%group_by(day)%>%mutate(groupmean=mean(logarea))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/6)/(SSW/511) 
})
#p-value: 
mean(Fs>obs_F)

#distribution of null distribution and test statistic: 
hist(Fs, prob = T); abline(v = obs_F, col = "red", add = T)
```
*For the randomization test, I calculated a randomized one-way ANOVA to see if mean logarea of the forest fires was equal across each day of the week. The null hypothesis is that mean logarea is the same across each day of the week. The alternative hypothesis is that mean logarea is different across at least one of the days of the week. The observed F statistic is 0.357 (p = 0.906, df=6). The simulated F statistic is 30.57223, much larger than the observed F statistic. The p-value is 0.9016, meaning that there is not a statistically significant difference between mean logarea and the day of the week that the forest fire occured on. As you can see from the distribution of the null distribution from the randomization test with the observed F statistic as the red line, only a small amount of the data sits below the actual F statistic, and the majority is greater than the actual F statistic, meaning the days do not differ by much in their logarea for the forest fire.* 

#3. Linear regresion model
```{r}
#linear regression model:
fitforest <- lm(meanlogarea ~ meanRH * meantemp * meanwind, data = forestdata)
summary(fitforest)

#checking linear regression assumptions: 
   #normality 
resids <- fitforest$residuals
shapiro.test(resids)

   #linearity 
fitvals <- fitforest$fitted.values
ggplot() + geom_point(aes(fitvals, resids)) + geom_hline(yintercept = 0, color = "red")

   #homoskedasticity 
library(sandwich)
library(lmtest)
bptest(fitforest)

#plot of linear regression: 
library(interactions)
interact_plot(fitforest, pred = meantemp, modx = meanwind, plot.points = TRUE)

#recomputed linear regression with robust standard errors: 
coeftest(fitforest, vcov=vcovHC(fitforest))
```
  *For this linear regression, I am investigating how wind, temperature, and relative humidity predict the logarea of a forest fire in this dataset. The null hypothesis is that the slope is 0 between each predictor (wind, temp, RH) and the response variable (logarea). The alternative hypothesis is that the slope is not 0 between each predictor (wind, temp, RH) and the response variable (logarea). For assumptions, normality was assesed with the Shapiro-Wilk test. The p-vaue for the test was 2.2e-16, meaning we reject the null and assume that the true distribution is not normal, failing to meet the normality assumption. For the test of linearity, a scatterplot was made for the fitted values vs. the residuals and does not represent full linearity for the model, so we also reject that assumption. For the homoskedasticity assumption, I ran the Breusch-Pagan test. The p-value for the BP test is 0.3494, being above the alpha value of 0.05, and accepting the null that the distribution of the model meets the assumptions of homoskedasticity.* 
  *Interpreting the coefficients of the model-main effects: -3.814e-02 hectares is the predicted mean logarea of forest burned when wind, temperature, and relative humidity are average. Controlling for temperature and wind, mean logarea of the forest burned increases 4.1966e-04 hectares for every one percent increase in relative humidity. Controlling for relative humidity and wind, mean logarea of the forest burned increases 2.2173e-02 hectares for every one degree celsius increase in temperature. Controlling for relative humidity and temperature, mean logarea of the forest burned increases 3.8575e-02 hectares for every one kilometer per hour increase in wind.*  
  *Interpreting the coeffecients of the model-interactions: Controlling for relative humidity, average temperature and wind have a significant interaction effect on log area of a forest fire, being a -1.430e-02 hectare decrease of logarea of a forest fire. When controlling for wind, there is a -1.291e-04 hectare decrease in logarea of a forest fire due to the interaction of average relative humidity and temperature. Controlling for temperature, there is a -8.964e-04 hectare decrease in logarea of a forest fire due to the interaction of relative humidity and wind. The interaction between average wind, temperature, and relative humidity results in a -8.254e-06 hectare decrease in logarea of a forest fire. For the entire model, the adjusted R^2 is 0.007705. This means that only 0.7705% of the variance in mean logarea of forest burned in hectares can be explained by mean relative humidity, mean temperature, and mean wind. As you can see from the interaction plot, the slope of mean log area of forest burned on mean temperature changes as a function of mean wind. Their interaction shows to be at 0 and 0 for both mean temperature and mean log area (where the lines intersect).*
  *When robsust standard errors were done for this model, the results that were significant stayed significant with slight changes to the p values. Controlling relative humidity before standard robust errors, the p-value for the interaction between temperature and wind on logarea of a forest fire was 0.021 and with robust standard errors the result stayed significant with a p-value of 0.01099. The intercept stayed significant as well with the same p-value being 2e-16.The estimates for the rest of the coefficients stayed relatively constant after this transformation of the standard errors.* 
  

#4. Bootstrapped standard errors linear regression model
```{r}
#bootstrapped standard errors: 
samp_distn<-replicate(5000, {
boot_dat<-boot_dat<-forestdata[sample(nrow(forestdata),replace=TRUE),]
fitdataforest <- lm(meanlogarea ~ meanRH * meantemp * meanwind, data = boot_dat)
coef(fitdataforest)
})

## Estimated SEs
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
samp_distn%>%t%>%as.data.frame%>%gather%>%group_by(key)%>%
summarize(lower=quantile(value,.025), upper=quantile(value,.975))
```
  *I calculated bootstrapped standard errors for the linear regression that is predicting mean logarea of a forest fire from average wind, temperature, and relative humidity. Comparing the bootstrapped standard errors to the original linear regression model, the standard errors are not much different, where they vary by hundreths of a decimal place. The bootstrapped standard errors in comparison to the robust standard errors are almost exactly the same, varying by a tiny amount that could be due to chance. All of the confidence intervals for main effects and interactions contain 0, the null value for the test, except for the interaction between mean temperature and mean wind. This result makes sense as this was the significant interaction in the regression ran above. No other effects became significant with the bootstrapped standard errors.*

#5. Logistic regression predicting binary variable
```{r}
#making dummy variable: 1= weekend (Friday, Saturday, Sunday), 0 = weekday (Monday, Tuesday, Wednesday, Thursday)
forestdata <- forestdata %>% mutate(day_b = ifelse(forestdata$day == c("fri", "sat", "sun"), 1, 0)) 
#model
forestdatafit <- glm(day_b ~ meanlogarea + meanDC, data = forestdata, family=binomial)
summary(forestdatafit)
exp(coef(forestdatafit))
#confusion matrix
probs <- predict(forestdatafit, type = "response")
table(predict=as.numeric(probs>.5),truth=forestdata$day_b)%>%addmargins
truth <- forestdata$day_b
#classification diagnostics: 
class_diag(probs, truth)

#ROC curve
library(plotROC) 
ROCplot<-ggplot(forestdata)+geom_roc(aes(d=day_b,m=probs), n.cuts=0) 
ROCplot
calc_auc(ROCplot)

#plot of log-odds
forestdata$logit<-predict(forestdatafit, type = "link") 
forestdata %>% ggplot()+geom_density(aes(logit,color = day_b, fill=day_b), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=day_b, fill = day_b))


```
   *I coded the day variable into weekend and weekdays, where 1 is equal to Friday, Saturday, and Sunday, and 0 is equal to Monday, Tuesday, Wednesday, and Thursday. I ran a logistic regression using mean log area and drought code to predict weekend or weekday. The only significant coefficient is for the intercept, having a p-value of 2e-16, and indicating that when logarea forest fire and drought code are both average, it is a 19.8%  chance that it is a weekend (the reference group) compared to being a weekday. Controlling for mean drought code, for every 1 unit increase in mean log area hectares of forest burned, the odds of it being a weekend are 0.9188 times the odds of it being a weekday. Controlling for mean log area of forest burned in hectares, the odds of it being a weekend are 0.9997794 times the odds of it being a weekday. When a confusion matrix was made for this regression, you can see that the accuracy is 0.8337, the sensitivty is 0, the specificity is 1, the precision is 0 (0/86), and the AUC is 0.5356796. The AUC shows that the model is bad at predicting. The sensitivity is 0 because 0 no positive values were predicted correctly, and the specificity is 1 because all values were being predicted to not be a weekend. When the ROC plot was made, it is almost a staight line (as bad as it could really get almost). This indicates the model is really not predicting well at all. The log-odds plot shows an odds density for only the negative values (being a weekday) as the true positive rate was 0, and the true negative rate was 1. This is just another example of how poorly the model is at predicting true positives.* 

#6. Logistic regression predciting binary variable from other variables 
```{r}
#logistic regression model:
newdata <- forestdata %>% select(c(X, Y, meanrain, meanISI, meantemp, meanRH, meanwind, meanlogarea, meanDC, day_b))
fit2 <- glm(day_b ~ (.)^2 , data= newdata, family = binomial)
summary(fit2)
probsforest <- predict(fit2, type = "response")
truthforest <- newdata$day_b
#in sample classification diagnostics: 
class_diag(probsforest, truthforest)

#10-fold cross validation and out of sample classification diagnostics: 
set.seed(1234)
k=10 

data<-newdata[sample(nrow(newdata)),] 
folds<-cut(seq(1:nrow(newdata)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){
  
  train<-newdata[folds!=i,] 
  test<-newdata[folds==i,]
  truth<-test$day_b
  
  
  fit<-glm(day_b~(.)^2,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  
  
  diags<-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean) 


#LASSO: 
library(glmnet)
responseforest<-as.matrix(newdata$day_b) 
probsforest<-model.matrix(fit2)[,-1] 


cv <- cv.glmnet(probsforest,responseforest, family="binomial") 


{plot(cv$glmnet.fit, "lambda", label=TRUE); abline(v = log(cv$lambda.1se)); abline(v = log(cv$lambda.min),lty=2)}

cv <- cv.glmnet(probsforest,responseforest, family="binomial")
lasso_fit<-glmnet(probsforest,responseforest,family="binomial",lambda=cv$lambda.1se)
coef(lasso_fit)

#10-fold cross validation on LASSO selected variables: 
set.seed(1234)
k=10 

data<-newdata[sample(nrow(newdata)),] 
folds<-cut(seq(1:nrow(newdata)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){
  
  train<-newdata[folds!=i,] 
  test<-newdata[folds==i,]
  truth<-test$day_b
  
  
  fit<-glm(day_b~X,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  
  
  diags<-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean) 

```
  *I started with mean centering the rest of the numeric explanatory variables and creating a new dataset so that only the variables of interest were included. I ran a model predicting all numeric variables (X, Y, rain, ISI, temperature, relative humidity, wind, log area, and drought code) from the binary weekend or weekday predictor (1= weekend (Friday, Saturday, Sunday), 0 = weekday (Monday, Tuesday, Wednesday, Thursday)). The coefficients listed produced significant p-values: Y:meanwind (p = 0.038873), meanISI:meantemp ( p = 8.6e-05), meanISI:meanDC (p = 0.007206), and meanISI:meanRH (p = 0.037450). In-sample classification diagnostics were run for this model. The accurary is 0.8413926, the sensitivity is 0.1046512, the specificity is 0.9883991, the precision is  0.6428571, and the AUC is 0.7200939. The AUC shows that the model is predicting fairly well. True positive rate (sensitivity) is low again as it was in the last model and true negative rate is high as it was in the last model as well. This shows that the cutoff may be too high for the model.*
  *I did a 10-fold cross validation with the same model above and calculated new classification diagnostics for out of sample. The accuracy is slightly lower being 0.8124057, the sensitivity is slightly lower being 0.06468254, the specificity is slightly lower being 0.9633189, and the AUC is much lower being 0.5688129. This AUC shows that the model is definitely overfitting as it decreased by approximately 0.1512. This AUC means that the model is bad at predicting and is overfitting. Due to the overfitting, I ran a LASSO and found that the only variable kept in the LASSO was X. I will proceed to run a new cross-validation and model only predicting based on X. After running the model with only X as an explanatory variable through cross-validation and running a new model, the accuracy is higher than the last CV being 0.8336727, the sensitivity has gone to 0, the specificity has gone to 1, and the AUC is 0.5199968. The AUC has gotten even lower and does not predict the model really at all/is greatly overfitting. This could be due to many reasons such as failed assumptions due to correlated variables, bad data that is not specific enough to the response variable and has confounding variables, or that these explanatory variables do not statistically predict day of the week.*
  
#Conclusion: 
  *After thoroughly investigating the forest fire data, you can see that some of the variables may be highly correlated due to them being related to weather and fire conditions, leading to difficulty in predicting them in a model. Transformations may need to occur in order to have a well-fitted model that can predict out of sample conditions. In order for forest fires to be better predicted in the future, this analysis shows that mean temperature and mean wind have an interaction that significantly effects the mean log area of a forest fire. I would suggest that researchers look into this interaction in the future in order to better prepare communities for forest fires. Thank you to Paulo Cortez and Aniíbal Morais from the University of Minho in Portugal for allowing me to use your data, and making it available to the public for further analyses.*
  
